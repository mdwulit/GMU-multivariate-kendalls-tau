---
title: "Multivariate Kendal's Tau"
author: 
  - Marek Dwulit
  - Magdalena Dwulit
date: "12/18/2016"
abstract: |
  In general, if $X$ and $Y$ bivariate probability distribution, the covariance is a one parameter which 
  indicates the amount of association between variable $X$ and variable $Y$. The covariance will be high
  and positive where there is hihgh probability that high values of $X$ are associated with high values
  of $Y$ and low values of $X$ are associated with low values of $Y$. On the other hand the if the 
  association is negative (high values of $X$ correspond to low values of $Y$ and low values of $X$ 
  correspond to high values of $Y) the correlation will be large and negative.
  
  This short text is an attempt to look for a way to capture concordence for multivariate
  probability distribution. In an nutshell, our method devides multidimensional space in to "quarters" and assigns 
  probability that two points drawn randomly from a data set will point in a given direction. 
  At the end of computation our method produces a vector of probabilites for eqch direction in multidimensional space.
  
  Finally this is a beggining of the work and the review is needed to established fisibility of proposed approach.
  Based of the outcome further effor will be provided to better define concept and polish the text. As of right now this
  document caputers more intuitive representation than formalized concepts.


output: pdf_document
---

### Assumption

For simplicity we are assuming that the points are generated from continous distribution. In other words 
we are assuming that there is no ties in any given dimension for all random vectors in data set. The
further work is needed to extend presented below concept in order to account for ties.

### Quarter Indexing 

Lets assume that we have a one dimensional space. Graphically we can represent it as a line with defined 0.
We have two halves and we can use binary system to indicate each half. Positive numbers are indicated by 1 and
negative numbers are indicated by 0. 

```{r, out.width = "200px", echo=FALSE}
knitr::include_graphics("Images/binary-one-dimension.png")
```

When we increease number of dimensions by one we have a plane devided into four quarters and we need two binary 
numbers to index all quarters. 

```{r, out.width = "200px", echo=FALSE}
knitr::include_graphics("Images/binary-two-dimension.png")
```

In the case of three dimensional space we have eight "quarters" and we can index all quarters with three binary numbers.

```{r, out.width = "200px", echo=FALSE}
knitr::include_graphics("Images/binary-three-dimension.png")
```

The rule for indexing quarter is rather obvious. First we observe that the number of "Quarters" is equal to $2^d$, where
d represents number of dimenstions. For each of the dimesions the value can be either bigger or smaller than zero (for 
now we will ingore case when value is 0). Therefore we need one bit per each dimension to index position of the point in
$d$ dimensial space. It is worth to notice that the index starts from 0 and ends at $2^d-1$

Furthermore it is important to notice that for each "quarter", there is an oposite "quarter"" indicated by the oposite vector
to a vector indicating point in a given quarter. By the nature of the binary indexing we can find the oposite quarter by performing the NOT operation on binary sequence indicating a given quarter. For a quarter marked by binary sequence $111$ (7 as an integer) the oposite quarter has index $000$ (0 as an integer).

```{r, out.width = "200px", echo=FALSE}
knitr::include_graphics("Images/binary-three-dimension-oposite-qtr.png")
```

### Locating two points in reference to eachother (identifying a quarter)

Using "quarter indexing"" is an useful scheme. The scheme allows to identify relational position of two points 
in a multidimensional space by indicating. As an example lets assume that we can have to vectors $\vec{x_1},\vec{x_2}$ indicating two points in the euclidan space.

If we want to define position of of $x_2$ in reference to $x_1$ we have to execute following operations:

1. $x_q=x_2-x_1$

2. Replace all positive values in $x_q$ with 1 and all negative values with 0

3. Translate binary sequence computed in previous step to decimal number

As an example we will use $x_1=(3, 4, 1)^T$ and $x_2=(5, 6, 3)^T$. First we subtract vectors $x_q=x_2-x_1 = (2,2,2)^T$. Then we create binary sequence applying rule listed in step two, so we have binary sequence $111$. Finally we translate binary sequnce to decimal number and we get 7th quarter. So we can conclude that point $x_2$ is located in 7-th quarter in reference to point $x_1$. 
By analogy if we check location of the point $x_1$ in reference to $x_2$ we will get quarter number 0 and we can conclude that the point $x_1$ is located in 0-th qarter in reference to point $x_2$.

```{r, out.width = "300px", echo=FALSE}
knitr::include_graphics("Images/binary-three-dimension-two-points-in-reference.png")
```

### Expressing Kendel's tau in terms of number of "quarters"

Interestingly, assuming that distribution is continous, we can express Kendel's tau estimator using introduced above quarter concept. Kendal's tau estimator is expreseed as follows:

(1)

$$
A_{ij}=sgn(X_i-X_j)*sgn(Y_i-Y_j) 
$$ 

where

(2)

$$
  sgn(u)=\begin{cases}
    1, & \text{if $u>0$}\\
    0, & \text{if $u>0$}\\
    -1, & \text{if $u<0$}
  \end{cases}
$$

(3)

$$
  T=\frac{\sum_{i=1}^{i=n-1}\sum_{j=i+1}^{j=n} A_{ij}}{\binom{n}{2}}
$$ 

To see how we can use quarter concept to estimate T, we have to recognize the fact that the formula nr 1 returns 1 for quarters 0 (00) and 3 (11) and returns -1 for quarters 1 (01) and 2 (10). Therefore we can interpret the nominator from the formula number (3) as a difference out of all possible pairs of points, between number pairs having other point in quarters 0 or 3, and pairs having other point in quarter 1 or 2. 

For the sake of simplicity we will refer to the two oposite quarters as a direction. So in $d$ dimensional space we have $2^{d-1}$ directions as per each direction we need two quarters. 

### Short discussion

Using concept of direction we can compute, out of all posible pairs, the number of points having
other point in a given direction and devide it by the number of all possible pairs.
The computed number would represent probability that a given pair of points will establish a given direction.
Intuitive speculation is that directions are independent (they are orthogonal to eachother) and thereofore
having vector of probabilites for each direction would reveal the nature of dataset in terms of monotnicity.

Furthermore if we assume that under $H_0$ there is no monotonicity present we know that for each pair, each of the direction is 
eqally likely. Threfore we know the probability distribution under $H_0$. So we can construct a test computing the p-value
for the vector of probabilites computed based on a given sample. Assuming that this pass the review the further work is 
necessary to construct the proper test.

Other aspect worth further investigation is to the problem of interpretation. Resulting vector of probabilites is a weak indicator,
meaning one has to put allot of effort to build intuition to interpret properly computed vector of probabilites. In other words the utility of the propose method is low. Therefore more work has to be done on making computed results more intuition firendly.


### Performance against artificial dataset

Below it will be perfomed the computetion to prove above theory.
For that purpose there will be four diffrent artificial data set generated. To do that it will be used diffrent matrix variance-covariance. For each of those there will be performed exponential transformation on the Z component.

It will be shown:

1. Matrix Variance-Covariance used to generate the data set.
2. Transformation applied  to "Z" component.
3. Scaterr plot ilustrating the generated data set and transformed data set.
4. 3D plot of data set and transformed data set.
5. Correlation Matrix for both data sets.
6. Counts and respect probabilities for each direction for both data sets. 


# Data set 1


```{r, echo=FALSE}
R = matrix(cbind(1.000000, -0.7, 0.951929,  
                 -0.7, 1.0000, -0.550000,  
                 0.951929, -0.5500, 1.000000),
           nrow=3)

# R = matrix(cbind(1.000000, -0.34321, 0.951929,  
#                  -0.34321, 1.0000, -0.550000,  
#                  0.951929, -0.5500, 1.000000),
#            nrow=3)

# R = matrix(cbind(1.000000, 0.1121, 0.851929,  
#                  0.112100, 1.0000, 0.140000,  
#                  0.851929, 0.1400, 1.000000),
#            nrow=3)

# R = matrix(cbind(1.0000, 0.00, 0.00,  
#                  0.00, 1.0000, 0.00,  
#                  0.00, 0.00, 1.0000),
#            nrow=3)
 
U = t(chol(R))
nvars = dim(U)[1]
numobs = 100
set.seed(1)
random.normal = matrix(rnorm(nvars*numobs,0,1), nrow=nvars, ncol=numobs);
X = U %*% random.normal
newX = t(X)

#Turn expotential transformation
newX[,3] <- exp(newX[,3])

#Ignore generated data and put hyperplane instead
# newX[,1]<-seq(1:100)
# newX[,2]<-(-seq(1:100))
# newX[,3]<-seq(1:100)

```

### Input Variance Covariance Matrix  

```{r, echo=FALSE}
raw = as.data.frame(newX)
orig.raw = as.data.frame(t(random.normal))
names(raw) = c("X","Y","Z")
cor(raw)
```

### Scatter plot

```{r, echo=FALSE}
plot(head(raw, numobs))
```

```{r, echo=FALSE}
bintodec <- function(y) {
  # find the decimal number corresponding to binary sequence 'y'
  if (! (all(y %in% c(0,1)))) stop("not a binary sequence")
  res <- sum(y*2^((length(y):1) - 1))
  return(res)
}

computeKendalProbVect <- function(newX) {
  qrtCount = rep(0, 2^(nvars-1))
  for(i in 1:(numobs-1)) {
    for(k in (i+1):numobs) {
      dx =  newX[k,] - newX[i,]
      p = as.integer(dx > 0)
      if (p[1] == 1) 
        p = (p != 1) ##Operation NOT to compute direction vs quarters (most significant bit is 0)
      p = bintodec(p)
      qrtCount[p+1] = qrtCount[p+1] + 1
    }
  }
  return(qrtCount)
}

qrtCountNoTrnsf <- computeKendalProbVect(t(X))
qrtCount <- computeKendalProbVect(newX)
```

### Counts and Probabilities depending on the quarter with Transforamtion

```{r, echo= FALSE}

qrtProb = qrtCount/choose(numobs, 2)


#Construct a matrix of Counts and Probabilities
B=as.matrix=cbind(qrtCount,qrtProb)


```

```{r results='asis', echo=FALSE}
df <- as.data.frame(t(B))
names(df)[names(df) == 'V1'] <- paste(tail(rev(as.integer(intToBits(0))),2),collapse = "")
names(df)[names(df) == 'V2'] <- paste(tail(rev(as.integer(intToBits(1))),2),collapse = "")
names(df)[names(df) == 'V3'] <- paste(tail(rev(as.integer(intToBits(2))),2),collapse = "")
names(df)[names(df) == 'V4'] <- paste(tail(rev(as.integer(intToBits(3))),2),collapse = "")


library(knitr)
out <- kable(df,format="markdown", align = 'c')
cat(gsub('\\bNaN\\b', '  ', out), sep='\n')
```

### Counts and Probabilities depending on the quarter with noTransforamtion

```{r, echo=FALSE}

qrtProbNoTrnsf = qrtCountNoTrnsf/choose(numobs, 2)

#Construct a matrix of Counts and Probabilities
C=as.matrix=cbind(qrtCountNoTrnsf,qrtProbNoTrnsf)
```


```{r results='asis', echo=FALSE}
df <- as.data.frame(t(C))
names(df)[names(df) == 'V1'] <- paste(tail(rev(as.integer(intToBits(0))),2),collapse = "")
names(df)[names(df) == 'V2'] <- paste(tail(rev(as.integer(intToBits(1))),2),collapse = "")
names(df)[names(df) == 'V3'] <- paste(tail(rev(as.integer(intToBits(2))),2),collapse = "")
names(df)[names(df) == 'V4'] <- paste(tail(rev(as.integer(intToBits(3))),2),collapse = "")


library(knitr)
out <- kable(df,format="markdown", align = 'c')
cat(gsub('\\bNaN\\b', '  ', out), sep='\n')
```

### Correlation Matrix 

```{r}

cor(newX)
cor(t(X))

```

### Tau matrix

```{r, echo=FALSE}
  tauMat <- matrix(NA, nrow = 2^(nvars-1), ncol = 2^(nvars-1))
  for (i in 1:(2^(nvars-1))) {
    for (j in 1:(2^(nvars-1))) {
      if (qrtCount[i]+qrtCount[j] == 0)
        tauMat[i,j] <- 0
      else
        tauMat[i,j] <- (qrtCount[i]-qrtCount[j])/(qrtCount[i]+qrtCount[j])
    }
  }
```

```{r results='asis', echo=FALSE}
df <- as.data.frame(tauMat)
names(df)[names(df) == 'V1'] <- paste(tail(rev(as.integer(intToBits(0))),2),collapse = "")
names(df)[names(df) == 'V2'] <- paste(tail(rev(as.integer(intToBits(1))),2),collapse = "")
names(df)[names(df) == 'V3'] <- paste(tail(rev(as.integer(intToBits(2))),2),collapse = "")
names(df)[names(df) == 'V4'] <- paste(tail(rev(as.integer(intToBits(3))),2),collapse = "")


library(knitr)
out <- kable(df,format="markdown", align = 'c')
cat(gsub('\\bNaN\\b', '  ', out), sep='\n')
```


